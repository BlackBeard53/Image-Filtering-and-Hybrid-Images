{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS x476 - Fall 2021\n",
    "# Project 1: Image Filtering and Hybrid Images\n",
    "\n",
    "## Brief\n",
    "* Due: Friday, 09/17/2021, 11:59PM\n",
    "\n",
    "* Hand-in: through Gradescope\n",
    "* Required files:\n",
    "  * `<your_gt_username>.zip`\n",
    "  * `<yout_gt_username>.pdf`\n",
    "  \n",
    "All projects in this course will be done with these jupyter notebooks. These are convenient ways for you to easily interact with your code. A notebook contains many blocks of code, each of which can be run independently.\n",
    "\n",
    "There are multiple ways that you can run a cell:\n",
    "1. Run the current cell, and stay in the current cell\n",
    "  * `ctrl+enter` on Windows and Linux\n",
    "  * `cmd+enter` on MacOS\n",
    "2. Run the current cell, move to the next cell:\n",
    "  * `shift+enter`\n",
    "  * click the \"Run\" button in the tool bar\n",
    "\n",
    "## Overview\n",
    "The goal of this assignment is to write an image filtering function and use it to create hybrid images using a simplified version of the SIGGRAPH 2006 [paper](https://stanford.edu/class/ee367/reading/OlivaTorralb_Hybrid_Siggraph06.pdf) by Oliva, Torralba, and Schyns. _Hybrid Images_ are static images that change in interpretation as a function of the viewing distance. The basic idea is that high frequency tends to dominate perception when it is available but, at a distance, only the low frequency (smooth) part of the signal can be seen. By blending the high frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances.\n",
    "\n",
    "This project is intended to build upon the basic PyTorch we did in Project 0, and introduce image filtering. Once you have created an image filtering function, it is relatively straightforward to construct hybrid images. If you don't already know Python, you may find [this resource](https://docs.python.org/3/tutorial/) helpful. If you're unfamiliar with PyTorch, the [tutorials](https://pytorch.org/tutorials/) from the official website are useful.\n",
    "\n",
    "We provide you with 5 pairs of aligned images which can be merged reasonably well into hybrid images. The alignment is super important because it affects the perceptual grouping (read the paper for details). We encourage you to create additional examples (e.g. change of expression, morph between different objects, change over time, etc.).\n",
    "\n",
    "For example, we can merge the two images below together:\n",
    "\n",
    "![Dog](https://dellaert.github.io/19F-4476/images/proj1/dog.jpg)\n",
    "\n",
    "![Cat](https://dellaert.github.io/19F-4476/images/proj1/cat.jpg)\n",
    "\n",
    "The low-pass (blurred) and high-pass versions of these images look like this:\n",
    "\n",
    "![Low Frequencies](https://dellaert.github.io/19F-4476/images/proj1/low_frequencies.jpg)\n",
    "\n",
    "![High Frequencies](https://dellaert.github.io/19F-4476/images/proj1/high_frequencies.jpg)\n",
    "\n",
    "The high frequency image is actually zero-mean with negative values, so it is visualized by adding 0.5. In the resulting visualization, bright values are positive and dark values are negative.\n",
    "\n",
    "As a result of merging these two images, we get this hybrid image:\n",
    "![Hybrid Image](https://dellaert.github.io/19F-4476/images/proj1/hybrid_image.jpg)\n",
    "\n",
    "If you're having trouble seeing the multiple interpretations of the image, a useful way to visualize the effect is by progressively downsampling the hybrid image as is done below:\n",
    "\n",
    "![Cat Hybrid Image Scales](https://dellaert.github.io/19F-4476/images/proj1/cat_hybrid_image_scales.jpg)\n",
    "\n",
    "We have provided a method `vis_image_scales_numpy()` in `utils.py`, which can be used to save and display such visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note:\n",
    "You will only be working in the following two files:\n",
    " - **`student_code.py`**\n",
    " - **`cutoff_standarddeviations.txt`**\n",
    "\n",
    "All the code that you need to add/replace lives in **`student_code.py`**. You will need to replace the cutoff standarddeviations in **`cutoff_standarddeviations.txt`**.\n",
    "\n",
    "### PLEASE DO NOT MODIFY OTHER FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "\n",
    "from proj1_code.utils import load_image, save_image, verify\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : 1D filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment relies on the concept of filtering signals. A [low pass filter](https://en.wikipedia.org/wiki/Low-pass_filter) removes the high-frequency components of a signal. \n",
    "\n",
    "To demonstarte the concepts of filtering in 1-D, we will use simple sine waves. These waves have just one frequency component and hence it will be easy to understand the effects of filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sinusoids\n",
    "\n",
    "In this part, we will dive into the concept behind low pass filtering and implement a Gaussian-kernel based low-pass filter.\n",
    "\n",
    "Let us start with [sinusoids](https://en.wikipedia.org/wiki/Sine_wave) in 1D: sinusoids are a family of sine functions with varying frequency, amplitude, and phase.\n",
    "\n",
    "$$f(x) = A \\text{sin} \\left(2 \\pi \\omega x + \\phi \\right)$$\n",
    "\n",
    "where $A$ is the amplitude, $\\omega$ is the frequency, and $\\phi$ is the phase.\n",
    "\n",
    "Let us now go through a utility function which will generate sinusoids for us for $x \\in [0, 5]$ given the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 40 # sampling frequency (i.e number of samples of x per second)\n",
    "x = torch.linspace(0, 5, int(5*fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_sinusoid(amplitude: float, frequency: float, phase: float) -> torch.Tensor:\n",
    "    # Generates sinusoids with given parameters on input x.\n",
    "    \n",
    "    return amplitude * torch.sin(2 * math.pi * frequency * x + phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_signals(x: torch.Tensor, y_list: List[torch.Tensor], y_labels: List[str]):\n",
    "    # Plots the 1d signals\n",
    "    plt.figure()\n",
    "    \n",
    "    for (y, label) in zip(y_list, y_labels):\n",
    "        plt.plot(x, y, label=label)\n",
    "        \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate two sinusoids: one low frequency and one high frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq_sinusoid = generate_1d_sinusoid(1, 0.4, 0)\n",
    "high_freq_sinusoid = generate_1d_sinusoid(1, 4, 0)\n",
    "plot_1d_signals(x, [low_freq_sinusoid, high_freq_sinusoid], ['low_freq', 'high_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now linearly combine both the sinusoids to create a new **combined signal**. This signal will serve as an example for low-pass filters where will try to recover the low-frequency sinusoid back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear addition of low_freq and high_freq sinusoid\n",
    "combined_signal = low_freq_sinusoid + high_freq_sinusoid\n",
    "plot_1d_signals(x, [combined_signal], ['complex_signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a signal with two frequency components. This can be useful to demonstrate low-pass filtering. Recall that low-pass filtering attenuates high-frequency components heavily, whereas the low-frequency components are left unchanged.\n",
    "\n",
    "We will now design a low pass filter which recovers the low-frequency component from the combined signal.\n",
    "\n",
    "Averaging operation is a good example of a low-pass filter. In this project, we will use averaging with Gaussian weights as a low-pass filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 1D Gaussian as Low-Pass filters\n",
    "\n",
    "A 1D Gaussian filter is of size $k$ is defined as: $$p(x; \\mu, \\sigma) = \\frac{1}{Z} \\exp \\left( -\\frac{\\left( x - \\mu \\right)^2}{2 \\sigma^2} \\right)$$\n",
    "where $Z$ is the normalizing coefficient such that the kernel sums to 1 over the range of the input $x \\in [0, k)$, $x$ being integers.\n",
    "\n",
    "The parameters $\\mu$ and $\\sigma$ are related to $k$ as:\n",
    "* kernel size $k = 4*\\sigma + 1$\n",
    "* mean $\\mu = \\lfloor\\frac{k}{2}\\rfloor$\n",
    "\n",
    "If we want to use this Gaussian kernel as a low-pass filter with cutoff frequency $\\omega_c$ (i.e. allow components with frequency $\\omega < \\omega_c$ pass through and attenuate components with higher frequency), we need to define the kernel parameters as follows:\n",
    "* standard deviation $\\sigma = \\frac{f_s}{2 \\pi \\omega_c}$.\n",
    "\n",
    "We can hence use $\\sigma$ as the paramterization of the kernel in this project. We can derive $k$ and $\\mu$ using $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TODO 1**:\n",
    "implement the function `create_1d_gaussian_kernel` in `student_code.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.student_code import create_1d_gaussian_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to visualize kernel\n",
    "def plot_kernel(kernel: torch.Tensor):\n",
    "    '''Plots the kernel'''\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(kernel)\n",
    "    plt.xlabel('idx')\n",
    "    plt.ylabel('p')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two components at frequency 0.4 and 4. Hence lets use 1.5 as the cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_frequency = 1.5\n",
    "standard_deviation = fs/(2*math.pi*cutoff_frequency)\n",
    "\n",
    "lowpass_1dfilter = create_1d_gaussian_kernel(standard_deviation)\n",
    "\n",
    "plot_kernel(lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_code.proj1_unit_tests.test_create_1d_gaussian_kernel as test_create_1d_gaussian_kernel\n",
    "\n",
    "print('test_tensor_datatype: ', \n",
    "      verify(test_create_1d_gaussian_kernel.test_tensor_datatype))\n",
    "print('test_create_kernel_with_sigma_int: ', \n",
    "      verify(test_create_1d_gaussian_kernel.test_create_kernel_with_sigma_int))\n",
    "print('test_kernel_sum: ',\n",
    "      verify(test_create_1d_gaussian_kernel.test_kernel_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**:\n",
    "* Does the plot look like a Gaussian function?\n",
    "* Does the unit test(s) pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Applying low-pass filter on combined signal (combination of sinusoids with two different frequencies)\n",
    "\n",
    "We want to use the Gaussian kernel we created to filter out the high frequency sinusoid. For this, you need to implement the function to perform 1D filtering. Let's check that our low-pass filter using Gaussian kernel is working as expected by filtering the low pass and high pass signal separately.\n",
    "\n",
    "### TODO 2:\n",
    "implement the function `my_1dfilter` in `student_code.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.student_code import my_1d_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying on low frequency signal\n",
    "filtered_low_freq_sinusoid = my_1d_filter(low_freq_sinusoid, lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_signals(x, [low_freq_sinusoid, filtered_low_freq_sinusoid], ['input', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying on low frequency signal\n",
    "filtered_high_freq_sinusoid = my_1d_filter(high_freq_sinusoid, lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the input\n",
    "plot_1d_signals(x, [high_freq_sinusoid, filtered_high_freq_sinusoid], ['input', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_code.proj1_unit_tests.test_my_1d_filter as test_my_1d_filter\n",
    "\n",
    "print('test_filter_with_box_kernel: ', \n",
    "      verify(test_my_1d_filter.test_filter_with_box_kernel))\n",
    "print('test_filter_with_asymmetric_kernel: ', \n",
    "      verify(test_my_1d_filter.test_filter_with_asymmetric_kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**:\n",
    "* Does the filter attenuate the high-frequency signal by a large magnitute, but the low-frequency signal is relatively unaffected\n",
    "* Does the unit test(s) pass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets observe what happens when we apply this filter to the combined signal\n",
    "filtered_combined_signal = my_1d_filter(combined_signal, lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_signals(x, [combined_signal, filtered_combined_signal, low_freq_sinusoid], ['input', 'output', 'original_low_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Implementing hybrid images in Pytorch manually\n",
    "\n",
    "**Gaussian Kernels.** Gaussian filters are used for blurring images.\n",
    "\n",
    "The multivariate Gaussian function is defined as:\n",
    "\n",
    "$$p(x;\\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2}\\det(\\Sigma)^{1/2}}\\exp\\bigg(-\\frac{1}{2}(x-\\mu)^\\top\\Sigma^{-1}(x-\\mu)\\bigg)$$\n",
    "\n",
    "where $n$ is equal to the dimension of $x$, $\\mu$ is the mean, and $\\Sigma$ is the covariance matrix. Similar to 1.2, we will use $\\sigma$ as the hyperparameter of the 2D kernel. The kernel shape is $(k,k)$ and the mean is $\\mu$ in each dimension. They are related to $\\sigma$ as:\n",
    "- $k = 4*\\sigma + 1$\n",
    "- $\\mu= \\begin{bmatrix} \\lfloor\\frac{k}{2}\\rfloor \\\\ \\lfloor\\frac{k}{2}\\rfloor \\end{bmatrix}$\n",
    "- $\\Sigma = \\begin{bmatrix} \\sigma^2 & 0 \\\\ 0 & \\sigma^2 \\end{bmatrix}$\n",
    "\n",
    "Alternatively, you can create a 2D Gaussian by taking the outer product of two vectors. Each such vector should have values populated from evaluating the 1D Gaussian PDF at each coordinate. The 1D Gaussian, as we saw in part 1.2, is defined as:\n",
    "$$p(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\mbox{exp} \\Bigg(-\\frac{1}{2\\sigma^2}(x-\\mu)^2 \\Bigg)$$\n",
    "\n",
    "\n",
    "\n",
    "Note that the sum of values in the 2D kernel should sum to 1.\n",
    "\n",
    "You will be implementing `create_2D_Gaussian_kernel()` that creates a 2D Gaussian kernel according to a free parameter, _standard deviation_, which controls how much low frequency to leave in the image. This is an important step for later in the project when you create hybrid images!\n",
    "\n",
    "**Image Filtering.** Image filtering (or convolution) is a fundamental image processing tool. See chapter 3.2 of Szeliski and the lecture materials to learn about image filtering (specifically linear filtering). You will be writing your own function to implement image filtering from scratch. More specifically, you will implement `my_imfilter()` which imitates the `filter2D()` function in the OpenCV library. As specified, your filtering algorithm must: (1) support grayscale and color images, (2) support arbitrarily-shaped filters, as long as both dimensions are odd (e.g. 7x9 filters, but not 4x5 filters), (3) pad the input image with zeros or reflected image content, and (4) return a filtered image which is the same resolution as the input image. We have provided an iPython notebook, `proj1_test_filtering.ipynb`, along with some tests (which are called in `proj1.ipynb`) to help you debug your image filtering algorithm. Note that there is a time limit of 5 minutes for a single call to `my_imfilter()`, so try to optimize your implementation if it goes over.\n",
    "\n",
    "**Hybrid Images.** A hybrid image is the sum of a low-pass filtered version of one image and a high-pass filtered version of another image. As mentioned in above, _cutoff standarddeviation_ controls how much high frequency to leave in one image and how much low frequency to leave in the other image. In `cutoff_standarddeviation.txt`, we provide a default value of 7 for each pair of images (the value on line _i_ corresponds to the cutoff value for the _i_-th image pair). You should replace these values with the ones you find work best for each image pair. In the paper it is suggested to use two cutoff (one tuned for each image) and you are free to try that as well. You will first implement `create_hybrid_image()` according to the starter code in `student_code.py`. Your function will call `my_imfilter()` using the kernel generated from `create_2d_gaussian_kernel()` to create low and high frequency images and then combine them into a hybrid image.\n",
    "\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.utils import load_image, save_image\n",
    "\n",
    "image1 = load_image('data/1a_dog.bmp')\n",
    "image2 = load_image('data/1b_cat.bmp')\n",
    "\n",
    "# display the dog and cat images\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image1*255).byte())\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image2*255).byte());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filter\n",
    "\n",
    "### TODO 3:\n",
    "You will first need to implement `create_2d_gaussian_kernel()` in `student_code.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.student_code import create_2d_gaussian_kernel\n",
    "from proj1_code.proj1_unit_tests.test_2d import verify_gaussian_kernel\n",
    "\n",
    "cutoff_standard_deviation = 7\n",
    "kernel = create_2d_gaussian_kernel(cutoff_standard_deviation)\n",
    "\n",
    "# let's take a look at the filter!\n",
    "plt.figure(figsize=(4,4)); plt.imshow(kernel);\n",
    "\n",
    "## Verify that the Gaussian kernel was created correctly\n",
    "print(verify_gaussian_kernel(kernel, cutoff_standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filter to image\n",
    "### TODO 4:\n",
    "The next two functions you need to implement in this project can also be found in `student_code.py`. Start by implementing `my_imfilter`, which takes both a filter and an image, and returns the filtered image. This code block will use your `my_imfilter` function to create and display a blurry version of image1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.student_code import my_imfilter\n",
    "\n",
    "blurry_image = my_imfilter(image1, kernel)\n",
    "\n",
    "plt.figure(); plt.imshow((blurry_image*255).byte());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid image\n",
    "\n",
    "### TODO 5:\n",
    "Next, implement `create_hybrid_image()` in `student_code.py`, which takes two images and makes a hybrid image using the low frequency content from one image and the high frequency content from another by applying the Gaussian kernel you defined in `create_2d_gaussian_kernel()`.\n",
    "\n",
    "Experiment with the value of `cutoff_standarddeviation` for each pair of images in `data/`. For each image pair, replace `cutoff_standarddeviations.txt` with the best cutoff standard deviation value you find. The value on line *i* of the text file should correspond to _i_-th image pair. This is an important step for the next part! Feel free to also experiment with which image in each pair you grab the low frequencies from and which image you grab high frequencies from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.student_code import create_hybrid_image\n",
    "from proj1_code.utils import vis_image_scales_numpy\n",
    "\n",
    "from proj1_code.proj1_unit_tests.test_2d import (\n",
    "    verify_low_freq_sq_kernel_torch_manual,\n",
    "    verify_high_freq_sq_kernel_torch_manual,\n",
    "    verify_hybrid_image_torch_manual\n",
    ")\n",
    "\n",
    "low_freq_image, high_freq_image, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "\n",
    "## Verify that results are as expected\n",
    "print(verify_low_freq_sq_kernel_torch_manual(image1, kernel, low_freq_image))\n",
    "print(verify_high_freq_sq_kernel_torch_manual(image2, kernel, high_freq_image))\n",
    "print(verify_hybrid_image_torch_manual(image1, image2, kernel, hybrid_image))\n",
    "\n",
    "vis = vis_image_scales_numpy(hybrid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.imshow((low_freq_image * 255).byte());\n",
    "plt.figure(); plt.imshow(((high_freq_image + 0.5) * 255).byte());\n",
    "plt.figure(figsize=(20, 20)); plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../results/part2\", exist_ok=True)\n",
    "save_image('../results/part2/low_freq_image.jpg', low_freq_image)\n",
    "save_image('../results/part2/high_freq_image.jpg', high_freq_image + 0.5)\n",
    "save_image('../results/part2/hybrid_image.jpg', hybrid_image)\n",
    "save_image('../results/part2/hybrid_image_scales.jpg', vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using PyTorch's inbuilt operators\n",
    "\n",
    "### TODO 6:\n",
    "**Dataloader:** You will now implement creating hybrid images again but using PyTorch. The `HybridImageDataset` class in `student_code.py` will create tuples using pairs of images with a corresponding cutoff standard deviation (which you should have found from experimenting in Part 2). The images will be loaded from `data/` and the cutoff standard deviation from `cutoff_standarddeviations.txt`. Refer to [this tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for additional information on data loading & processing.\n",
    "\n",
    "### TODO 7:\n",
    "**Model:** Next, you will implement the `HybridImageModel` class in `student_code.py`. Instead of using your implementation of `my_imfilter()` to get the low and high frequencies from a pair of images, `low_pass()` should use the 2d convolution operator from `torch.nn.functional` to apply a low pass filter to a given image. You will have to implement `get_kernel()` which calls your `create_2d_gaussian_kernel()` function for each pair of images using the cutoffs as specified in `cutoff_standarddeviations.txt` and reshapes it to the appropriate dimensions for PyTorch. Then, similar to `create_hybrid_image()` from Part 2, `forward()` will call `get_kernel()` and `low_pass()` to create the low and high frequency images and combine them into a hybrid image. Refer to [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) for additional information on defining neural networks using PyTorch.\n",
    "\n",
    "Lastly, you will compare the runtimes of your hybrid image implementations from Parts 2 and 3.\n",
    "\n",
    "Make sure you have specified a cutoff value in `cutoff_standarddeviations.txt` for each image pair in `data/` before executing the following blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from proj1_code.student_code import HybridImageDataset\n",
    "from proj1_code.student_code import HybridImageModel\n",
    "\n",
    "\n",
    "data_root = 'data/' # if you're using additional data, make sure to change this to '../additional_data'\n",
    "cf_file = 'cutoff_standarddeviations.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model & dataset\n",
    "Implement `HybridImageModel` and `HybridImageDataset` in `student_code.py`.\n",
    "\n",
    "In the code documentation, you will see a term called \"batch size\", which we will discuss in later projects and lectures. For now, we are using the default value of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid images\n",
    "This code block will iterate through pairs of images from your dataset and create a hybrid image using the low frequency content from one image and the high frequency content from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(dataloader):\n",
    "    image_a, image_b, cutoff_standarddeviation = sample\n",
    "    low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff_standarddeviation)\n",
    "    \n",
    "    os.makedirs(\"../results/part3\", exist_ok=True)\n",
    "    # saves low frequencies, high frequencies, and hybrid image of each pair of images\n",
    "    torchvision.utils.save_image(low_frequencies, '../results/part3/%d_low_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(high_frequencies+0.5, '../results/part3/%d_high_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(hybrid_image, '../results/part3/%d_hybrid_image.jpg' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that the results are correct, with cutoff_frequency of 7\n",
    "from proj1_code.proj1_unit_tests.test_2d import (\n",
    "    verify_low_freq_sq_kernel_pytorch, \n",
    "    verify_high_freq_sq_kernel_pytorch,\n",
    "    verify_hybrid_image_pytorch\n",
    ")\n",
    "\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "image_a, image_b, cutoff = next(iter(dataloader))\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff)\n",
    "\n",
    "cutoff_sd = torch.Tensor([7])\n",
    "## On first dog/cat pair, verify that the Pytorch results are as expected\n",
    "print(verify_low_freq_sq_kernel_pytorch(image_a, model, cutoff_sd, low_frequencies))\n",
    "print(verify_high_freq_sq_kernel_pytorch(image_b, model, cutoff_sd, high_frequencies))\n",
    "## Verify that the Pytorch hybrid images are created correctly\n",
    "print(verify_hybrid_image_pytorch(image_a, image_b, model, cutoff_sd, hybrid_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid image timing comparison\n",
    "Here, we will compare the runtime of creating hybrid images using your manual Torch implementation to the PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image1 = load_image('data/1a_dog.bmp')\n",
    "image2 = load_image('data/1b_cat.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 2. Notice that we explicitly include `create_2D_Gaussian_kernel()` in the timing of Part 2 but not Part 3. This is because the function is already being called (and therefore timed) inside the forward pass of `HybridImageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cutoff_standarddeviation = 7\n",
    "kernel = create_2d_gaussian_kernel(cutoff_standarddeviation)\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "end = time.time() - start\n",
    "print('Part 1: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "\n",
    "start = time.time()\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, torch.Tensor([cutoff_standarddeviation]))\n",
    "end = time.time() - start\n",
    "print('Part 2: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filtering\n",
    "\n",
    "In this section, we will implement a median filter and apply it on an image (grayscale only). A median filter is a non-linear filter that is used for noise reduction in images / other signals. For a window of size $(N, N)$, a median filter replaces the center pixel of the neighborhood with the median value of all the pixels in the window. An example of a 2D median filter is given below:\n",
    "\n",
    "![median_filter](./data/median_filter.jpeg \"Median Filter\")\n",
    "\n",
    "In the above example, a kernel of size $3 \\times 3$ is applied over a region of the image and the center pixel is being replaced by the value $9$, which is the median of all the pixel values in this region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8:\n",
    "\n",
    "Implement the `my_median_filter` function in `student_code.py` file based on the given below information:\n",
    "- The input image will always be a grayscale image of dimensions $(m, n, 1)$ or $(m, n)$.\n",
    "- The filter size will always be odd and it can either be a scalar value or a tuple of integers\n",
    "- The output must be a tensor of dimensions $(m, n, 1)$. To ensure that the spatial resolution remains the same, you need to use zero-padding.\n",
    "\n",
    "Let us load the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_img = Image.open('data/median_filter_test.jpeg').convert('L')\n",
    "plt.figure(figsize=(5,5)); plt.imshow((np.array(median_img)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying median filter \n",
    "Here, we will apply the median filter on the above given image. Test several different values for filter size and observe the differences in the output. \n",
    "1. What happens to the corners of the images when the filter size is very large? Is there a simple explanation for the same?\n",
    "2. Think of a few methods to avoid the above issue (if any). Are there an disadvantages of using these methods over simple zero padding of the input image?\n",
    "3. Apply the median filter on the coin.png image given in the data folder. Is the median filter able to remove the noise to a certain extent? Can we use a Gaussian filter instead of the median filter for the same purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from student_code import my_median_filter\n",
    "median_img_torch = torch.tensor(np.array(median_img), dtype=torch.float)\n",
    "\n",
    "# Code output\n",
    "my_output = my_median_filter(median_img_torch, (7, 7))\n",
    "my_output = my_output.squeeze(2).numpy()\n",
    "\n",
    "plt.figure(figsize=(5,5)); plt.imshow((np.array(my_output)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Extra Credit\n",
    "\n",
    "## _This part is optional for undergraduate students (4476), but required for graduate students (6476)_\n",
    "\n",
    "In this section, we will learn about formulating the Discrete Fourier Transform matrix, and use it to run DFT for 2D images, and implement a low-pass filter based on your DFT analysis results. \n",
    "\n",
    "### DFT for 2D signal\n",
    "\n",
    "An N-point DFT is expressed as the multiplication $X=Wx$, where $x$ is the original input signal, $W$ is the N-by-N square DFT matrix, and $X$ is the DFT of the signal. The [wiki](https://en.wikipedia.org/wiki/DFT_matrix) provides a good introduction on DFT matrix for a 1D signal. The DFT equation for a 2D square matrix is:\n",
    "$$U_{mn}=\\frac{1}{M}e^{-j\\frac{2\\pi mn}{M}}$$\n",
    "where $M=N$. \n",
    "\n",
    "### TODO 8:\n",
    "Implement the `dft_matrix` in `student_code.py` function based on the given information.\n",
    "\n",
    "In this part, we begin with a simple situation where we assume all the 2D image matrices are square, grayscale matrices, which would make your life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_unit_tests.test_dft import test_dft_matrix\n",
    "\n",
    "print(test_dft_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image filtering based on Discrete Fourier Transform (DFT)\n",
    "\n",
    "A brief review on the DFT for 2D images:\n",
    "$$F[k,l]=\\sum_{m=0}^{M-1}\\sum_{n=0}^{N-1}f[m,n]exp(-j\\frac{2\\pi}{M}km-j\\frac{2\\pi}{N}ln)$$\n",
    "where $$0\\leq k \\leq M-1$$ $$0\\leq l \\leq N-1$$\n",
    "\n",
    "We observe that the DFT transform of each row is independent from that of the column. This means in order to obtain the 2D DFT transform, we can run a 1D DFT of then columns, then a 1D DFT of rows consecutively (or rows first, then columns). That would save us a lot of computation!\n",
    "\n",
    "### TODO 9:\n",
    "We can now use the `dft_matrix` function in `student_code.py` to generate DFT for a normal image, and implement the function `my_dft`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_unit_tests.test_dft import test_dft\n",
    "\n",
    "print(test_dft())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate low-pass filter!\n",
    "\n",
    "### TODO 10:\n",
    "Finally, we implement a low-pass filter based on your own DFT, and add the results of the following images to your report. :`data_part4/6a_dog.bmp`, `data_part4/6b_cat.bmp`; the resolution is 512x512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from proj1_code.student_code import dft_filter\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "image6 = Image.open('data_part4/6a_dog.bmp')\n",
    "image_gray = transforms.ToTensor()(image6)[0,:,:]\n",
    "img_dft_filter = dft_filter(image_gray)\n",
    "\n",
    "plt.subplot(121), plt.imshow(image_gray, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(img_dft_filter, cmap = 'gray')\n",
    "plt.title('Filtered Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Extra Credit (for ALL)\n",
    "### Impressive Hybrid Images\n",
    "\n",
    "It is also possible to get extra credit for this project as well if you come up with some clever hybrid images which impress the TAs and Frank. Additionally, you should add slides at the end of your report further showing your results. The best ones get a special mention from Frank at the beginning of one of the future lectures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forbidden functions\n",
    "\n",
    "You can use these for testing, but not in your final code: anything that takes care of the filtering operation or creates a 2D Gaussian kernel directly for you. ex. (cv2.getGaussianKernel) If it feels like you're sidestepping the work, then it's probably not allowed. Ask the TAs if you have any doubts.\n",
    "\n",
    "# Code Testing\n",
    "\n",
    "We have provided a set of tests for you to evaluate your implementation. We have included tests inside `proj1.ipynb` so you can check your progress as you implement each section. When you're done with the entire project, you can call additional tests by running `pytest proj1_unit_tests` inside the `proj1_code` directory of the project. _Your grade on the coding portion of the project will be further evaluated with a set of tests not provided to you._\n",
    "\n",
    "# Writeup\n",
    "\n",
    "For this project (and all other projects), you must do a project report using the template slides provided to you at \"proj1_template.pptx\". Do <u>not</u> change the order of the slides or remove any slides, as this will affect the grading process on Gradescope and you will be deducted points. In the report you will describe your algorithm and any decisions you made to write your algorithm a particular way. Then you will show and discuss the results of your algorithm. The template slides provide guidance for what you should include in your report. A good writeup doesn't just show results--it tries to draw some conclusions from the experiments. You must convert the slide deck into a PDF with the name `<your_gt_username.pdf>` for your submission.\n",
    "\n",
    "If you choose to do anything extra, add slides _after the slides given in the template deck_ to describe your implementation, results, and analysis. Adding slides in between the report template will cause issues with Gradescope, and you will be deducted points. You will not receive full credit for your extra credit implementations if they are not described adequately in your writeup. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please check your assignment completion\n",
    "\n",
    "### Required for all\n",
    "* `create_1d_gaussian_kernel()`\n",
    "* `my_1d_filter()`\n",
    "* `create_2d_gaussian_kernel()`\n",
    "* `my_imfilter()`\n",
    "* `create_hybrid_image()`\n",
    "* `make_dataset()`\n",
    "* `get_cutoff_standarddeviations()`\n",
    "* `HybridImageDataset#__init__()`\n",
    "* `HybridImageDataset#__len__()`\n",
    "* `HybridImageDataset#__getitem__()`\n",
    "* `HybridImageModel#get_kernel()`\n",
    "* `HybridImageModel#low_pass()`\n",
    "* `HybridImageModel#forward()`\n",
    "* `my_median_filter()`\n",
    "\n",
    "### Report\n",
    "* Answer all the questions on the report correctly\n",
    "\n",
    "### Required for 6476 students, Optional for 4476 students\n",
    "* `dft_matrix()`\n",
    "* `my_dft()`\n",
    "* `dft_filter()` results in the report\n",
    "\n",
    "\n",
    "### Note\n",
    "* Additional hybrid images will be awarded extra credits, graded on creativity and originality\n",
    "* Lose 5 points for every time you do not follow the instructions for the hand-in format.\n",
    "\n",
    "\n",
    "# Submission\n",
    "\n",
    "This is very important as you will lose 5 points for every time you do not follow the instructions. \n",
    "\n",
    "Do <u>not</u> install any additional packages inside the conda environment. The TAs will use the same environment as defined in the config files we provide you, so anything that's not in there by default will probably cause your code to break during grading. Do <u>not</u> use absolute paths in your code or your code will break. Use relative paths like the starter code already does. Failure to follow any of these instructions will lead to point deductions. Create the zip file using `python zip_submission.py --gt_username <your_gt_username>` (it will zip up the appropriate directories/files for you!) and hand it through Gradescope. Remember to submit your report as a PDF to Gradescope as well.\n",
    "\n",
    "# Credit\n",
    "- Assignment developed by Arvind Krishnakumar, Ayush Baid, Sen Wang and Frank Dellaert, based on a similar project by James Hays, Derek Hoiem, Cusuh Ham, John Lambert and Samarth Brahmbhatt.<br/>\n",
    "- Assignment modified and re-structured by Junyan Mao, Shashank Srikanth in Fall 2021."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
